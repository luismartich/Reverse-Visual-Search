{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfukeCX91Kkb",
        "outputId": "0def9434-94cb-4962-92c0-f7385a496f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from torchvision.io import read_image\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torchvision import models, transforms\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Convolution2D, MaxPooling2d, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "#from keras.applications import VGG16\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(model, image):\n",
        "\n",
        "  preprocess = weights.transforms()\n",
        "\n",
        "  batch = preprocess(image).unsqueeze(0)\n",
        "\n",
        "  prediction = model(batch).squeeze(0).softmax(0)\n",
        "  class_id = prediction.argmax().item()\n",
        "  score = prediction[class_id].item()\n",
        "  category_name = weights.meta[\"categories\"][class_id]\n",
        "  print(f\"{category_name}: {100 * score:.2f}%\")\n",
        "\n",
        "directory_name = r'/content/drive/MyDrive/CS482/coco_minitrain_25k/images/train2017/'\n",
        "dir = os.listdir(directory_name)\n",
        "\n",
        "\n",
        "#https://pytorch.org/vision/stable/models.html >> USED THIS <<\n",
        "#pretrained model weights (currently alias for IMAGENET1K_V2)\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "#model using pretrained model weights\n",
        "model = resnet50(weights=weights)\n",
        "# Set model to eval mode\n",
        "model.eval()\n",
        "count = 0\n",
        "for img in dir:\n",
        "  if count > 10:\n",
        "    break\n",
        "# https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html >> USED THIS <<\n",
        "  process_image(model, read_image(directory_name + img))\n",
        "  count += 1\n",
        "  \n",
        "knn_index = {\n",
        "    \"settings\": {\n",
        "        \"index.knn\": True\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"zalando_img_vector\": {\n",
        "                \"type\": \"knn_vector\",\n",
        "                \"dimension\": 2048\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "7fuV5MOU1O4s",
        "outputId": "2dd23b36-646a-44eb-bda6-85ec79cbc01a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5e313078f0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdirectory_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/content/drive/MyDrive/CS482/coco_minitrain_25k/images/train2017/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Extraction Class\n",
        "\n",
        "class featureExtractor(nn.Module):\n",
        "  def __init__(self,model):\n",
        "    super(featureExtractor, self).__init__()\n",
        "    self.features = list(model.features)\n",
        "    self.features = nn.Sequential(*self.features)\n",
        "    self.pooling = model.avgpool\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = model.classifier[0]\n",
        "  def forward(self, x):\n",
        "      out = self.features(x)\n",
        "      out = self.pooling(out)\n",
        "      out = self.flatten(out)\n",
        "      out = self.fc(out) \n",
        "      return out \n",
        "model = models.vgg16(pretrained=True)\n",
        "new_model = featureExtractor(model)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "new_model = new_model.to(device)"
      ],
      "metadata": {
        "id": "U7TpvPH6dGc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterating through directory and extracting features from each image\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.CenterCrop(512),\n",
        "    transforms.Resize(448),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "features = []\n",
        "for img in dir:\n",
        "  img_path = directory_name + img\n",
        "  image = cv2.imread(img_path)\n",
        "  image = transform(image)\n",
        "  image = image.reshape(1,3,448,448)\n",
        "  image = image.to(device)\n",
        "  with torch.no_grad():\n",
        "    feature = new_model(image)\n",
        "  features.append(feature.cpu().detach().numpy().reshape(-1))\n",
        "features = np.array(features)"
      ],
      "metadata": {
        "id": "8XqSFohvdIQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing out what labels were given to each image from directory we went over\n",
        "from sklearn.cluster import KMeans\n",
        "model = KMeans(n_clusters = 5, random_state = 42)\n",
        "model.fit(features)\n",
        "labels = model.labels_\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "RZNJf2YEdOv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}